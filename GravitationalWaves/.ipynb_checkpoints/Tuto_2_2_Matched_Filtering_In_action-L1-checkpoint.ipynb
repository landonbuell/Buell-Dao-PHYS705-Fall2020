{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "d9O1zsAO1zul"
   },
   "source": [
    "<img style=\"float: left;padding: 1.3em\" src=\"https://indico.in2p3.fr/event/18313/logo-786578160.png\">  \n",
    "\n",
    "#  Gravitational Wave Open Data Workshop #3\n",
    "\n",
    "\n",
    "## Tutorial 2.2 PyCBC Tutorial, Matched Filtering in Action\n",
    "\n",
    "We will be using the [PyCBC](http://github.com/ligo-cbc/pycbc) library, which is used to study gravitational-wave data, find astrophysical sources due to compact binary mergers, and study their parameters. These are some of the same tools that the LIGO and Virgo collaborations use to find gravitational waves in LIGO/Virgo data \n",
    "\n",
    "In this tutorial we will walk through how find a specific signal in LIGO data. We present matched filtering in PyCBC, which is optimal in the case of Gaussian noise and a known signal model. In reality our noise is not entirely Guassian, and in practice we use a variety of techniques to separate signals from noise in addition to the use of the matched filter. \n",
    "\n",
    "Additional [examples](http://pycbc.org/pycbc/latest/html/#library-examples-and-interactive-tutorials) and module level documentation are [here](http://pycbc.org/pycbc/latest/html/py-modindex.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "chV5GUKV1zup"
   },
   "source": [
    "## Installation (execute only if running on a cloud platform!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "hPydO5B_1zuq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'gwpy==1.0.1'\"\n"
     ]
    }
   ],
   "source": [
    "# -- Use the following for Google Colab\n",
    "! pip install -q 'lalsuite==6.66' 'PyCBC==1.15.3'\n",
    "#! pip install -1 'gwpy==1.0.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "KkcI-Bah1zuw"
   },
   "source": [
    "**Important:** With Google Colab, you may need to restart the runtime after running the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "cJ9NEh-q1zuw"
   },
   "source": [
    "### Looking for a specific signal in the data\n",
    "\n",
    "If you know what signal you are looking for in the data, then matched filtering is known to be the optimal method in Gaussian noise to extract the siganl. Even when the parameters of the signal are unkown,  one can test for each set of parameters one is interesting in finding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "4rvbMKWW1zux"
   },
   "source": [
    "#### preconditioning the data \n",
    " \n",
    "The purpose of this is to reduce the dynamic range of the data and  supress low freqeuncy behavior which can introduce numerical artefacts. We may also wish to reduce the sample rate of the data if high frequency content is not important. PyCBC contains an interface to the GWOSC catalog, so you can easily access the data and parameters of the published gravitational-wave signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "id": "8VSW4sca1zuy",
    "outputId": "5bce84a1-1cd0-40d9-ffc3-c10814e3cb9c"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycbc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e93efc96b735>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpycbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatalog\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMerger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpycbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mresample_to_delta_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhighpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcurve_fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycbc'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pycbc.catalog import Merger\n",
    "from pycbc.filter import resample_to_delta_t, highpass\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# As an example we use the GW150914 data\n",
    "merger = Merger(\"GW150914\")\n",
    "#merger = Merger(\"GW150914\")\n",
    "\n",
    "# Get the data from the Hanford detector\n",
    "strain = merger.strain('L1')\n",
    "\n",
    "# Remove the low frequency content and downsample the data to 2048Hz\n",
    "strain = highpass(strain, 15.0)\n",
    "strain = resample_to_delta_t(strain, 1.0/2048)\n",
    "\n",
    "plt.plot(strain.sample_times, strain)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "sHJcsujM1zu1"
   },
   "source": [
    "_Note_: To read data from a local file instead of from the GWOSC server, we can use the [pycbc.frame.read_frame(file, channel_name)](https://github.com/gwastro/pycbc/blob/master/docs/frame.rst) method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "qqXqAIMx1zu2"
   },
   "source": [
    "#### filter wraparound \n",
    "\n",
    "Note the spike in the data at the boundaries. This is caused by the highpass and resampling stages filtering the data. When the filter is applied to the boundaries, it wraps around to the beginning of the data. Since the data itself has a discontinuity (i.e. it is not cyclic) the filter itself will ring off for a time up to the length of the filter. \n",
    "\n",
    "Even if a visible transient is not seen, we want to avoid filters that act on times which are not causally connect. To avoid this we trim the ends of the data sufficiently to ensure that they do not wraparound the input. We will enforce this requirement in all steps of our filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "id": "nthrNAfz1zu2",
    "outputId": "ccc96393-caca-498b-d419-b68aa0c61bc2"
   },
   "outputs": [],
   "source": [
    "# Remove 2 seconds of data from both the beginning and end\n",
    "conditioned = strain.crop(2, 2)\n",
    "\n",
    "plt.plot(conditioned.sample_times, conditioned)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "1oVFXwS-1zu5"
   },
   "source": [
    "#### calculate the power spectral density\n",
    "\n",
    "Optimal matched filtering requires weighting the frequency components of the potential signal and data by the noise amplitude. We can view this as filtering the data with the time series equivelant of 1 / PSD. To ensure that we can control the effective length of the filter, we window the time domain equivalent of the PSD to a specific length. This has the effect of losing some information about line behavior in the detector, however, since our signals span a large frequency range, and lines are narrow, this is a negligible effect.\n",
    "\n",
    "Important note: Computing a PSD from data that might contain signals, non-Gaussianities and non-stationarities is not trivial. In this example we use Welch's method to obtain a PSD estimate. PyCBC's PSD module contains tools for measuring PSDs, or directly using pre-generated PSDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "lBNv_Jod1zu5"
   },
   "outputs": [],
   "source": [
    "from pycbc.psd import interpolate, inverse_spectrum_truncation\n",
    "# Estimate the power spectral density\n",
    "\n",
    "# We use 4 second samples of our time series in Welch method.\n",
    "psd = conditioned.psd(4)\n",
    "\n",
    "# Now that we have the psd we need to interpolate it to match our data\n",
    "# and then limit the filter length of 1 / PSD. After this, we can\n",
    "# directly use this PSD to filter the data in a controlled manner\n",
    "psd = interpolate(psd, conditioned.delta_f)\n",
    "\n",
    "# 1/PSD will now act as a filter with an effective length of 4 seconds\n",
    "# Since the data has been highpassed above 15 Hz, and will have low values\n",
    "# below this we need to inform the function to not include frequencies\n",
    "# below this frequency. \n",
    "psd = inverse_spectrum_truncation(psd, 4 * conditioned.sample_rate,\n",
    "                                  low_frequency_cutoff=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "ScKiCSQv1zu7"
   },
   "source": [
    "#### make your signal model\n",
    "\n",
    "Conceptually, matched filtering involves laying the potential signal over your data and integrating (after weighting frequencies correctly). If there is a signal in the data that aligns with your 'template', you will get a large value when integrated over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "colab_type": "code",
    "id": "iDa3oHLc1zu8",
    "outputId": "72c63d8a-2611-47a1-bb6f-9fb5eb409a84"
   },
   "outputs": [],
   "source": [
    "from pycbc.waveform import get_td_waveform\n",
    "# In this case we \"know\" what the signal parameters are. In a search\n",
    "# we would grid over the parameters and calculate the SNR time series\n",
    "# for each one\n",
    "\n",
    "# We'll assume equal masses, and non-rotating black holes which is within the posterior probability\n",
    "# of GW150914. \n",
    "m = 36 # Solar masses\n",
    "hp, hc = get_td_waveform(approximant=\"SEOBNRv4_opt\",\n",
    "                     mass1=m,\n",
    "                     mass2=m,\n",
    "                     delta_t=conditioned.delta_t,\n",
    "                     f_lower=30)\n",
    "\n",
    "# We will resize the vector to match our data\n",
    "hp.resize(len(conditioned))\n",
    "\n",
    "# The waveform begins at the start of the vector, so if we want the\n",
    "# SNR time series to correspond to the approximate merger location\n",
    "# we need to shift the data so that the merger is approximately at the \n",
    "# first bin of the data.\n",
    "\n",
    "# The cyclic_time_shift method shifts the timeseries by a given amount of time.\n",
    "# It treats the data as if it were on a ring so points shifted off the end\n",
    "# of the series reappear at the start. Note that time stamps are *not* in\n",
    "# general affected (as the start time of the full array is shifted),\n",
    "# but the index of each point in the vector is.\n",
    "#\n",
    "# By convention waveforms returned from `get_td_waveform` have their\n",
    "# merger stamped with time zero, so we can use the start time to \n",
    "# shift the merger into position\n",
    "plt.figure()\n",
    "plt.title('Before shifting')\n",
    "plt.plot(hp.sample_times, hp)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Strain')\n",
    "\n",
    "template = hp.cyclic_time_shift(hp.start_time)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('After shifting')\n",
    "plt.plot(template.sample_times, template)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Strain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "eq3a8qI71zvB"
   },
   "source": [
    "#### calculating the signal-to-noise time series\n",
    "\n",
    "In this section we will now calculate the signal-to-noise time series for our template. We'll take care to handle issues of filter corruption / wraparound by truncating the output time series. We need to account for both the length of the template and 1 / PSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "5D-a0-iu1zvC",
    "outputId": "0b1c8b8a-ebbf-4007-f46f-9ea24a6a0982",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pycbc.filter import matched_filter\n",
    "import numpy\n",
    "\n",
    "snr = matched_filter(template, conditioned,\n",
    "                     psd=psd, low_frequency_cutoff=30)\n",
    "\n",
    "# Remove time corrupted by the template filter and the psd filter\n",
    "# We remove 4 seonds at the beginning and end for the PSD filtering\n",
    "# And we remove 4 additional seconds at the beginning to account for\n",
    "# the template length (this is somewhat generous for \n",
    "# so short a template). A longer signal such as from a BNS, would \n",
    "# require much more padding at the beginning of the vector.\n",
    "snr = snr.crop(4 + 4, 4)\n",
    "\n",
    "# Why are we taking an abs() here?\n",
    "# The `matched_filter` function actually returns a 'complex' SNR.\n",
    "# What that means is that the real portion correponds to the SNR\n",
    "# associated with directly filtering the template with the data.\n",
    "# The imaginary portion corresponds to filtering with a template that\n",
    "# is 90 degrees out of phase. Since the phase of a signal may be \n",
    "# anything, we choose to maximize over the phase of the signal.\n",
    "plt.figure(figsize=[10, 4])\n",
    "plt.plot(snr.sample_times, abs(snr))\n",
    "plt.ylabel('Signal-to-noise')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.show()\n",
    "\n",
    "peak = abs(snr).numpy().argmax()\n",
    "snrp = snr[peak]\n",
    "time = snr.sample_times[peak]\n",
    "\n",
    "print(\"We found a signal at {}s with SNR {}\".format(time, \n",
    "                                                    abs(snrp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "IKZl57RG1zvE"
   },
   "source": [
    "### Aligning and Subtracting the Proposed Signal\n",
    "\n",
    "In the previous section we found a peak in the signal-to-noise for a proposed binary black hole merger. We can use this SNR peak to align our proposal to the data, and to also subtract our proposal from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "iP2NKJ8h1zvF"
   },
   "outputs": [],
   "source": [
    "from pycbc.filter import sigma\n",
    "# The time, amplitude, and phase of the SNR peak tell us how to align\n",
    "# our proposed signal with the data.\n",
    "\n",
    "# Shift the template to the peak time\n",
    "dt = time - conditioned.start_time\n",
    "aligned = template.cyclic_time_shift(dt)\n",
    "\n",
    "# scale the template so that it would have SNR 1 in this data\n",
    "aligned /= sigma(aligned, psd=psd, low_frequency_cutoff=20.0)\n",
    "\n",
    "# Scale the template amplitude and phase to the peak value\n",
    "aligned = (aligned.to_frequencyseries() * snrp).to_timeseries()\n",
    "aligned.start_time = conditioned.start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "QZ5rXcyC1zvH"
   },
   "source": [
    "#### Visualize the overlap between the signal and data\n",
    "\n",
    "To compare the data an signal on equal footing, and to concentrate on the frequency range that is important. We will whiten both the template and the data, and then bandpass both the data and template between 30-300 Hz. In this way, any signal that is in the data is transformed in the same way that the template is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "BtGiJC651zvI",
    "outputId": "680655af-d69d-4cfa-f3d1-a18266b6f206",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We do it this way so that we can whiten both the template and the data\n",
    "shift = 1.126259462e+9 #shift by this amount in plotting to get time in seconds\n",
    "white_data = (conditioned.to_frequencyseries() / psd**0.5).to_timeseries()\n",
    "white_template = (aligned.to_frequencyseries() / psd**0.5).to_timeseries()\n",
    "\n",
    "white_data = white_data.highpass_fir(20., 512).lowpass_fir(300, 512)\n",
    "white_template = white_template.highpass_fir(20, 512).lowpass_fir(300, 512)\n",
    "\n",
    "# Select the time around the merger\n",
    "white_data = white_data.time_slice(merger.time-.15, merger.time+.05)\n",
    "white_template = white_template.time_slice(merger.time-.15, merger.time+.05)\n",
    "\n",
    "\n",
    "plt.figure(figsize=[12, 5])\n",
    "plt.plot(white_data.sample_times-shift, white_data, label=\"Data\")\n",
    "plt.plot(white_template.sample_times-shift, white_template, label=\"Template\")\n",
    "plt.legend()\n",
    "plt.ylim(-120,120)\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize=[12, 5])\n",
    "# plt.plot(white_data.sample_times, white_data - white_template, label=\"Data\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the first inspiral near merger time\n",
    "### Fit function $f(t) = A e^{-\\gamma t} \\cos(\\frac{\\omega t}{t - t_{m}} + \\delta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_data = (conditioned.to_frequencyseries() / psd**0.5).to_timeseries()\n",
    "white_template = (aligned.to_frequencyseries() / psd**0.5).to_timeseries()\n",
    "\n",
    "white_data = white_data.highpass_fir(20., 512).lowpass_fir(300, 512)\n",
    "white_template = white_template.highpass_fir(20, 512).lowpass_fir(300, 512)\n",
    "\n",
    "#define the time of inspiral event\n",
    "white_data = white_data.time_slice(merger.time-.1, merger.time+0.02)\n",
    "white_template = white_template.time_slice(merger.time-.1, merger.time+0.02)\n",
    "\n",
    "def OsccilatingFunction(x, A, E, w, s, g):\n",
    "    return A*np.cos(w*x/(x-E) + s)*np.exp(-(g*x))\n",
    "\n",
    "plt.figure(figsize=[12, 5])\n",
    "plt.plot(white_data.sample_times-shift, white_data, label=\"Data\")\n",
    "plt.plot(white_template.sample_times-shift, white_template, label=\"Template\")\n",
    "plt.ylim(-120,120)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begins Fitting to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax = np.asarray(white_data.sample_times-shift)\n",
    "datay = np.asarray(white_data)\n",
    "plotx = np.linspace(min(datax),max(datax),1000)\n",
    "\n",
    "start_vals = np.array([10000.0021, .4960, 15.33006,1.90315,-35.1]) #initial guess\n",
    "param_dict=['A','E','w','s','g']\n",
    "\n",
    "popt,pcov = optimize.curve_fit(OsccilatingFunction,xdata=datax,ydata=datay,p0=start_vals,maxfev=10000000)\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(\"{:>11s}\".format(\"\"),end=\"\")\n",
    "for i in range(len(popt)):\n",
    "    print(\"{:>11s}\".format(param_dict[i]),end=\"\")\n",
    "print(\"\")\n",
    "for i in range(len(popt)):\n",
    "    print(\"{:>11s}\".format(param_dict[i]),end=\"\")\n",
    "    for j in range(len(popt)):\n",
    "        print(\"{:11.2e}\".format(pcov[i,j]),end=\"\")\n",
    "    print(\"\")\n",
    "\n",
    "print(\"Fit results:\")\n",
    "print(\"Parameters:\")\n",
    "for i,(p,pe) in enumerate(zip(popt,np.sqrt(np.diag(pcov)))):\n",
    "    print(\"{:4s}  {:8.5f} ± {:8.5f}\".format(param_dict[i],p,pe))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,5)) \n",
    "ax.plot(plotx,OsccilatingFunction(plotx,*popt[0:6]), label = \"fit result\")\n",
    "plt.plot(datax,datay)\n",
    "plt.ylim(-120,120)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 0.38s the fit is off we try again from 0.30 to 0.38s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_data = (conditioned.to_frequencyseries() / psd**0.5).to_timeseries()\n",
    "white_template = (aligned.to_frequencyseries() / psd**0.5).to_timeseries()\n",
    "\n",
    "white_data = white_data.highpass_fir(20., 512).lowpass_fir(300, 512)\n",
    "white_template = white_template.highpass_fir(20, 512).lowpass_fir(300, 512)\n",
    "\n",
    "white_data = white_data.time_slice(merger.time-.15, merger.time-0.01)\n",
    "white_template = white_template.time_slice(merger.time-.15, merger.time-0.01)\n",
    "\n",
    "\n",
    "plt.figure(figsize=[12, 5])\n",
    "plt.plot(white_data.sample_times-shift, white_data, label=\"Data\")\n",
    "plt.plot(white_template.sample_times-shift, white_template, label=\"Template\")\n",
    "plt.legend()\n",
    "plt.ylim(-100,100)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "datax = np.asarray(white_data.sample_times)-shift\n",
    "datay = np.asarray(white_data)\n",
    "\n",
    "start_vals = np.array([1.41298, 0.55, 10.30128,13.49541,-10.90879])\n",
    "param_dict=['A','E','w','s','g']\n",
    "\n",
    "popt,pcov = optimize.curve_fit(OsccilatingFunction,xdata=datax,ydata=datay,p0=start_vals,maxfev=10000000)\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(\"{:>11s}\".format(\"\"),end=\"\")\n",
    "for i in range(len(popt)):\n",
    "    print(\"{:>11s}\".format(param_dict[i]),end=\"\")\n",
    "print(\"\")\n",
    "for i in range(len(popt)):\n",
    "    print(\"{:>11s}\".format(param_dict[i]),end=\"\")\n",
    "    for j in range(len(popt)):\n",
    "        print(\"{:11.2e}\".format(pcov[i,j]),end=\"\")\n",
    "    print(\"\")\n",
    "\n",
    "print(\"Fit results:\")\n",
    "print(\"Parameters:\")\n",
    "for i,(p,pe) in enumerate(zip(popt,np.sqrt(np.diag(pcov)))):\n",
    "    print(\"{:4s}  {:8.5f} ± {:8.5f}\".format(param_dict[i],p,pe))\n",
    "\n",
    "plotx = np.linspace(min(datax),max(datax),1000)\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,5)) \n",
    "ax.plot(plotx,OsccilatingFunction(plotx,*popt[0:5]), label = \"fit result\")\n",
    "plt.plot(datax,datay)\n",
    "plt.ylim(-100,100)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit the ring-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_data = (conditioned.to_frequencyseries() / psd**0.5).to_timeseries()\n",
    "white_template = (aligned.to_frequencyseries() / psd**0.5).to_timeseries()\n",
    "\n",
    "white_data = white_data.highpass_fir(20., 512).lowpass_fir(300, 512)\n",
    "white_template = white_template.highpass_fir(20, 512).lowpass_fir(300, 512)\n",
    "\n",
    "white_data = white_data.time_slice(merger.time+.0185, merger.time+0.05)\n",
    "white_template = white_template.time_slice(merger.time+.0185, merger.time+0.05)\n",
    "\n",
    "datax = np.asarray(white_data.sample_times)-shift\n",
    "datay = np.asarray(white_data)\n",
    "\n",
    "\n",
    "def DampingFunction(x, A, w, s, g):\n",
    "    return A*np.cos(w*x + s)*np.exp(-g*x)\n",
    "\n",
    "\n",
    "x2 = np.linspace(min(datax),max(datax),1000)\n",
    "y2 = DampingFunction(x,100,500.,1,20)\n",
    "\n",
    "plt.figure(figsize = (12,5))\n",
    "#plt.plot(x2,y2,'r')\n",
    "plt.plot(datax,datay)\n",
    "plt.ylim(-120,120)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "param_dict=['A','w','s','g']\n",
    "\n",
    "start_vals = np.array([-100000.843, -800.48760, 1.77006,5.80315])\n",
    "\n",
    "plotx = np.linspace(min(datax),max(datax),1000)#np.linspace(min(datax),max(datax),1000)/1126259462*10e+8 - 1000000000\n",
    "data_range = (datax>min(datax)) & (datax<max(datax))\n",
    "\n",
    "popt,pcov = optimize.curve_fit(DampingFunction,xdata=datax,ydata=datay,p0=start_vals,maxfev=100000)\n",
    "print(\"=\"*20)\n",
    "print(\"{:>11s}\".format(\"\"),end=\"\")\n",
    "for i in range(len(popt)):\n",
    "    print(\"{:>11s}\".format(param_dict[i]),end=\"\")\n",
    "print(\"\")\n",
    "for i in range(len(popt)):\n",
    "    print(\"{:>11s}\".format(param_dict[i]),end=\"\")\n",
    "    for j in range(len(popt)):\n",
    "        print(\"{:11.2e}\".format(pcov[i,j]),end=\"\")\n",
    "    print(\"\")\n",
    "\n",
    "print(\"Fit results:\")\n",
    "print(\"Parameters:\")\n",
    "for i,(p,pe) in enumerate(zip(popt,np.sqrt(np.diag(pcov)))):\n",
    "    print(\"{:4s}  {:8.5f} ± {:8.5f}\".format(param_dict[i],p,pe))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,5)) \n",
    "ax.plot(plotx,DampingFunction(plotx, *popt),color = 'r',label=\"Fit Result\")\n",
    "plt.plot(datax,datay,'b')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the fit parameters back to the funtion, be careful with A = 0.00000000 and very large A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_data = (conditioned.to_frequencyseries() / psd**0.5).to_timeseries()\n",
    "white_template = (aligned.to_frequencyseries() / psd**0.5).to_timeseries()\n",
    "\n",
    "white_data = white_data.highpass_fir(20., 512).lowpass_fir(300, 512)\n",
    "white_template = white_template.highpass_fir(20, 512).lowpass_fir(300, 512)\n",
    "\n",
    "#plot the whole range \n",
    "white_data = white_data.time_slice(merger.time-.15, merger.time+.05)\n",
    "white_template = white_template.time_slice(merger.time-.15, merger.time+.05)\n",
    "\n",
    "datax = np.asarray(white_data.sample_times) - shift\n",
    "\n",
    "xdata = np.linspace(min(x),max(x),len(datax)) \n",
    "ydata = np.zeros(len(datax))\n",
    "\n",
    "x = np.linspace(min(datax),max(datax),409)\n",
    "y = OsccilatingFunction(x, 0.0000006, 0.46913, 5.13236,-38.78739,-45.57235)\n",
    "\n",
    "x2 = np.linspace(min(datax),max(datax),409)\n",
    "y2 = DampingFunction(x2 , 1206371114449438935927853274838633283584.00000, -1449.78698, 274.20640, 203.80018)\n",
    "\n",
    "x0 = np.linspace(min(datax),max(datax),409)\n",
    "y0 =  OsccilatingFunction(x0, -0.12660, 0.57739, 22.63191,36.09615,-14.10774)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stitch each part of the fit together and make them look nicer. Very tedious "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x0)):\n",
    "    if x0[i] >  0.387:\n",
    "        y0[i] = 0\n",
    "        \n",
    "for i in range(len(x)):\n",
    "    if x[i] >  0.41796875:\n",
    "        y[i] = 0\n",
    "    if x[i] < 0.387:\n",
    "        y[i] = 0\n",
    "\n",
    "for i in range(len(x2)):\n",
    "    if x2[i] < 0.41799999:\n",
    "        y2[i] = 0\n",
    "\n",
    "combined_fit = y0 + y +y2 \n",
    "\n",
    "\n",
    "plt.figure(figsize = (12,5)) \n",
    "plt.plot(white_data.sample_times-1.126259462e+9, white_data, label=\"Data\")\n",
    "#plt.plot(white_template.sample_times-1.126259462e+9, white_template, color = 'b',label=\"Template\")\n",
    "plt.plot(x0,combined_fit,color = 'red' ,label=\"Fit\")\n",
    "plt.legend()\n",
    "plt.ylim(-110,120)\n",
    "plt.show()\n",
    "\n",
    "#plot residual\n",
    "plt.figure(figsize = (12,5))\n",
    "plt.plot(white_data.sample_times-shift,white_template - white_data, color = 'b',label = \"Template residual\")\n",
    "plt.plot(white_data.sample_times-shift,combined_fit - white_data, color = 'r',label = \"Fit residual\")\n",
    "plt.ylim(-50,50)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the chirp mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chirpMass(f,fdot,c,G):\n",
    "    return ((c**3/G*(5/96*np.pi**(-8/3)*fdot/(f**(11/3)))**(3/5))/(1.99e+30))\n",
    "\n",
    "c = 3.00e+8\n",
    "G = 6.674e-11\n",
    "dt = .42-.385\n",
    "f = 3.0/dt\n",
    "fdot = f/dt\n",
    "chirpMass(f,fdot,c,G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "rE7zEPsq1zvK"
   },
   "source": [
    "#### Subtracting the signal from the data\n",
    "\n",
    "Now that we've aligned the template we can simply subtract it. Let's see below how that looks in the time-frequency plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "colab_type": "code",
    "id": "6IwKtDRz1zvK",
    "outputId": "1821dd02-59ce-4255-bf8f-d597bdecc11b"
   },
   "outputs": [],
   "source": [
    "subtracted = conditioned - aligned\n",
    "\n",
    "# Plot the original data and the subtracted signal data\n",
    "\n",
    "for data, title in [(conditioned, 'Original H1 Data'),\n",
    "                    (subtracted, 'Signal Subtracted from H1 Data')]:\n",
    "\n",
    "    t, f, p = data.whiten(4, 4).qtransform(.001,\n",
    "                                                  logfsteps=100,\n",
    "                                                  qrange=(8, 8),\n",
    "                                                  frange=(20, 512))\n",
    "    plt.figure(figsize=[15, 5])\n",
    "    plt.title(title)\n",
    "    plt.pcolormesh(t, f, p**0.5, vmin=0, vmax=10)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.xlim(merger.time - .2, merger.time + .1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "mTPmoPRV1zvM"
   },
   "source": [
    "## Challenge!\n",
    "\n",
    "Use the methods demonstrated above to see if you can calculate the SNR\n",
    "time series in the following data sets. What is the SNR of each signal?\n",
    "Which template matched best to which data?\n",
    "\n",
    "Information that may be useful:\n",
    "\n",
    "* Signals are all placed between 100 and 120 seconds into the frame file.\n",
    "* You may assume mass1 = mass1 (equal mass) and that each component mass is one of 15, 30, or 45.\n",
    "* Each file starts at gps time 0, and ends at gps time 128\n",
    "* The channel name in each file is \"H1:TEST-STRAIN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "SZYbZO9K1zvP",
    "outputId": "26434e05-56bf-4880-8f9d-41f27fd81f32"
   },
   "outputs": [],
   "source": [
    "# Download the challenge set files\n",
    "from pycbc.frame import read_frame\n",
    "import urllib\n",
    "\n",
    "def get_file(fname):\n",
    "    url = \"https://github.com/gw-odw/odw-2020/raw/master/Data/{}\"\n",
    "    url = url.format(fname)\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "    print('Getting : {}'.format(url))\n",
    "\n",
    "files = ['PyCBC_T2_0.gwf', 'PyCBC_T2_1.gwf', 'PyCBC_T2_2.gwf']\n",
    "\n",
    "for fname in files:\n",
    "    get_file(fname)\n",
    "    \n",
    "\n",
    "# An example of how to read the data from these files:\n",
    "file_name = \"PyCBC_T2_0.gwf\"\n",
    "\n",
    "# LOSC bulk data typically uses the same convention for internal channels names\n",
    "# Strain is typically IFO:LOSC-STRAIN, where IFO can be H1/L1/V1.\n",
    "channel_name = \"H1:TEST-STRAIN\"\n",
    "\n",
    "start = 0\n",
    "end = start + 128\n",
    "\n",
    "ts = read_frame(file_name, channel_name, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tuto_2.2_Matched_Filtering_In_action.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
